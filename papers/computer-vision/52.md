## Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering

#### Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, Devi Parikh. CVPR 2017.

#### Summary

This paper proposes to tackle the language priors and biases present in the original VQA dataset by balancing the dataset. Specifically, the authors propose to find complementary images for each question-image pair such that the complementary image has a different answer for the question. Thus, by construction, the entropy of answers on a per question level will increase and this will result in heavier tails in the statistics of the answers, leading to impoverished language biases which existing VQA models current exploit to perform as well as they do.

The authors propose a novel data collection protocol where they ask AMT workers to pick an image from a set of 24 nearest neighbor images (nearest to the original image in the question-image pair), such that the question is still valid for the picked image but the answer is not. They then acquire 10 answers for each of these complementary images, resulting in not only a balanced dataset, but also a 2x larger dataset.

To illustrate the effects of balancing, the authors benchmark existing state-of-the-art VQA models on the balanced dataset and see that these models when trained on the unbalanced dataset and tested on the balanced dataset, perform significantly worse. Also, the overall performance for train and test on the balanced dataset is also lower than on the unbalanced dataset, empirically showing the reduced bias in the dataset.

As a final novelty, the authors also demonstrate a new modality of model explanation, where the VQA model now not only returns an answer prediction but also returns a counter-example image, i.e. an image that is semantically similar to the input image but which the model believes does not have the same answer. This novelty is a direct extension of thei data collection protocol. This explanation modality enables the user of the model to have more faith in the model's capabilities.

#### Strengths

1. Balancing of the dataset tackles a severe problem in VQA of language priors and biases, thus allowing for researchers to truly make advances towards intelligent agents.
2. New modality for explanation is very novel and easy to interpret.
3. Illustrations and benchmarks show that the balancing is effective and model weaknesses are readily exposed.
4. Since this paper fixes a lot of issues in a prior work, it is hard to find faults, and my list of paper weaknesses may be easily rebuttaled. If I was a CVPR 2017 reviewer, this would be a definite yes from me. :)

#### Weaknesses

1. Given that the authors tested AMT workers for trustworthiness, it would have been nice to see multiple workers vote on the complementary image for the question-answer pair. Perhaps this would have helped with other issues such as ones encountered in the counter-example explanations?
2. No particular reasoning given for choosing VGG16 features for nearest neighbor computations.
3. The augmentation of the test set with 18K additional question-image pairs is not elaborated on and is confusing why this is done. What sort of anomalous trends are the authors expecting?


#### Reflections

This is a solid paper that addresses the shortcomings of the original VQA dataset. The key insight here for me would be to be able to train models that find the subtle differences in the complementary images, since this would be a good way to enable better fine-grained scene understanding, which is currently an active area of research (examples include human in the loop for fine grained recognition). This dataset enables this sort of work beyond simple VQA and indeed, this is what the overall goal of my course project is, since it took a fair bit of inspiration from this paper.  