## You Only Look Once: Unified, Real-Time Object Detection

#### Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi. CVPR 2016.

#### Summary

This paper proposes YOLO, a joint framework for object detection that localizes and classifies objects in images using a single pass. This is in contrast to other approaches which are 2 stage, the first for region proposals and the second for bounding box classification.

The model divides the image into a grid, where each box is responsible for predicting both the object class as well as the bounding box. In the paper, each box predicts two of these boxes, each having its left hand coordinate and the height and width. The boxes are weighed by the class prediction, thus stronger class predictions have more influence. Subsequently, the authors propose a multi-task loss that does this classification and detection in a joint fashion.

In experiments, the authors show that YOLO is 9x faster than state of the art object detection pipelines while being only a few mAP points below them. This makes YOLO a useful framework for real time object detection.

#### Strengths

1. Fast object detection.
2. Simple way of letting the network learn from images directly in an end to end fashion.
3. Intuitive multitask formulation.

#### Weaknesses

1. The network seems to be biased towards a specific subset of object orientations.
2. The network does poorly on small objects.
