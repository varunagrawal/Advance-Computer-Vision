## Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions

#### Arijit Ray, Gordon Christie, Mohit Bansal, Dhruv Batra, Devi Parikh. EMNLP 2016.

#### Summary

This paper proposes to tackle the problem of question relevance in VQA. Specifically, the authors propose techniques to classify questions as either visual or no, or as being relevant to / grounded in the accompanying image in order to imbue models with the ability to point out the irrelevance rather than provide a non-sensical answer.

To this end, the authors collect 2 datasets, one for reasoning about whether a question is a visual question, i.e. does the question need an image in order to be answered called VNQ, and another to answer whether the question is based on a true premise with regard to the image called VTFQ. The authors tackle this task in a 2 stage process, first evaluating whether the question is visual, and if yes, whether it is a true- or false-premise question. For the first stage, the authors propose to use an LSTM that is trained on the Part of Speech tag of the question to have the LSTM learn the structure of a visual question so it generalizes across domains. As a baseline, the authors use a hand-crafted Rule base approach.

For the second stage, the authors tackle this using 2 different approaches. The first approach uses the inherent uncertainty in the VQA model itself when it answers a question in order to gauge if the question is grounded in the image. To this end, the authors use an entropy based approach, calculating the entropy of the output of the VQA model and training a MLP on it, and alternatively they use an MLP to directly classify if the VQA model output is from a visually grounded image or not. The second approach involves using LSTMs to generate the image caption as well as generate a valid question given the image. The idea here is that if there is similarity between the caption and the original question or the original question and the generated question, the question is likely to be visually grounded in the image. The baseline for this second approach is a classifier under the learned question generation model.

In terms of experiments, the authors show that their proposed techniques outperform the baselines. The authors also present a human user study, where given the question and answers from 120 different VQA questions for each a baseline VQA model and their question relevance trained model, the users are tasked with picking which model gives "more reasonable" answers. The results show that the model trained with question relevance is picked significantly more. The paper concludes with a short discussion of future work. 

#### Strengths

1. The problem being tackled is very valid for real world scenarios.
2. Easy to implement and integrate approaches described.
3. Human user study instills confidence in the techniques.

#### Weaknesses

1. The authors could have potentially created a much larger VNQ dataset by using all the images in the COCO train split since the non-visual questions could be anything. Why this is not done is not explained.
2. The authors claim the Rule Based approach to detecting visual questions is a strong baseline. This is validated by any means since once could hash a sentiment analysis problem as a visual question classification problem and then leverage the rich set of tools and approaches in that space to create a truly strong baseline to compare against.
3. The authors claim that the uncertainty in the VQA model translates to poor visual grounding of the question seems to be misplaced. The space of possible images and questions is enormous and thus uncertainty would mostly be from novel combinations of valid questions to the corresponding images, without leading to any type of quantification about the question's relevance. This is also seen in the results of the experiments.
4. The fact that the users in the human user study seem to pick the question relevance model over the baseline model even when both get their respective answers wrong seems counterintuitive, since as a user, I would like the model to at least answer my question rather than be stubborn about the incorrect question relevance and thus fail to fulfill its service to me. Some more analysis on this aspect would have been useful.

#### Reflections

This paper is pretty straightforward and quite short. The ideas are well presented and the paper proposes simple data driven methods to tackle a valid problem. Some of the possible future avenues of work are mentioned in the paper and they seem like very good directions. An interesting idea that came to me is using this approach during the dataset creation phase in order to give the AMT worker a sense of how good their question is, similar to a password strength indicator. This could potentially be used as a reporting metric to quantify the visual nature of the questions as well as the applicability of the question's premise to the image, perhaps not only in VQA but with a little more thought for any dataset that deals with vision and language.